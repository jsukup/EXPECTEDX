{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Techniques -- Beyond K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding the similarities and differences in data is a foundational challenge to any business's data strategy. Whether it's identifying customers with shared nuances and idiosyncrasies or determining homogeneous gene sequences for cancer research, several techniques exist for grouping data -- otherwise known as clustering to the data science world or segmentation to the business world.\n",
    "\n",
    "One of the most commonly used methods by analytics practitioners is K-Means Clustering. Its easy-to-understand process and variety of applications make it a popular technique and probably the first (if not only) clustering method taught to statistics students. Yet for all that K-Means is good for, it isn't a panacea. Like all statistical modeling methods it has its pros, cons, and of course, underlying assumptions. Today we're going to explore alternative clustering techniques to K-Means for situations were its performance can be suboptimal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assumptions of K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of brevity, I'll assume the reader has an understanding of how K-Means works (for a refresher, go [here](https://en.wikipedia.org/wiki/K-means_clustering)). Some of the underlying assumptions that make K-Means an efficient clustering technique (especially on the very large data sets you'd expect to find in a productionized big data solution) also can be its greatest weaknesses. While there's no doubt that K-Means will cluster any data you feed into it, the resulting clusters may not realistically capture the underlying relationships an analyst seeks to find.\n",
    "\n",
    "Let's explore three assumptions of K-Means that, if violated, can result in poor or downright inaccurate clusters:\n",
    "\n",
    "* The number of clusters is known beforehand.\n",
    "* Data is roughly spherical and easily separable.\n",
    "* Clusters are approximately the same size.\n",
    "\n",
    "It should be noted that even when these assumptions *are* met, the iterative nature and randomized placement of centroids at algorithm initialization can lead K-Means to cluster data differently with each run if not reach convergence at local optima rather than global. As with any statistical technique, never blindly apply and accept the results!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The number of clusters is known beforehand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Means requires the number of clusters to be determined before the algorithm is run. This requires some level of understanding about the data structure that an analyst may not have knowledge of. For example,"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
