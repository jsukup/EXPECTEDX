{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hawai'i Island Hotels: TripAdvisor Review Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *John E. Sukup III, Principal Consultant, Expected X*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visitor reviews of vacation lodging are an important source of information for hotel and resort management. A traditional approach to gathering this data would be via surveys, comment cards, or even phone transcriptions to customer service call centers. A modern approach to gleaning insights from visitors can be accomplished via natural language processing (NLP) of reviews left on websites such as TripAdvisor. \n",
    "\n",
    "With this approach, visitors are in an environment where they can openly share their opinions in a natural way without the interference of a researcher. They are allowed to freely express their opinions in their own words without prompting as done in a survey. Biases usually introduced by the subjectivity of a researcher are all but eliminated, however it should be noted that visitors' reviews could be influenced by reading other reviews prior to writing their own. Also, considerations should be made that visitors providing reviews to websites like TripAdvisor are self-selecting so an argument about how representative the sample is could be made.\n",
    "\n",
    "Nevertheless, I believe the positives outweigh the negatives and that meaningful, if not actionable, insights can be extracted from visitor hotel reviews. The goal of this study will be to learn what underlying themes are reoccuring in positive and negative reviews using Latent Dirichlet Allocation (LDA) for Topic Modeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\analyticsdev\\Anaconda\\lib\\site-packages\\gensim\\utils.py:865: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim import corpora, models\n",
    "from gensim.utils import simple_preprocess\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping TripAdvisor Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TripAdvisor offers and [API](https://developer-tripadvisor.com/content-api/) but does not allow the API to be called for gathering hotel reviews for research purposes. This means one needs to resort to web scraping in order to gather reviews and metadata relating to them.\n",
    "\n",
    "While a number of web scraping tools exist such as [Octoparse](http://www.octoparse.com/) I chose to stay within the Python environment for all stages of this project. Python also has a number of web scraping packages. I chose Scrapy due to its relatively easy to understand coding structure.\n",
    "\n",
    "Scrapy has an extensive number of features for production-level web scraping but for this research only a base scraper was needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from tripadvisor.items import TripadvisorItem\n",
    "\n",
    "class TrSpider(scrapy.Spider):\n",
    "    name = 'trspider'\n",
    "    start_urls = [\n",
    "            'https://www.tripadvisor.com/Hotels-g29217-Island_of_Hawaii_Hawaii-Hotels.html'\n",
    "            ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        for href in response.xpath('//div[@class=\"listing_title\"]/a/@href'):\n",
    "            url = response.urljoin(href.extract())\n",
    "            yield scrapy.Request(url, callback=self.parse_hotel)\n",
    "\n",
    "        next_page = response.xpath('//div[@class=\"unified pagination standard_pagination\"]/child::*[2][self::a]/@href')\n",
    "        if next_page:\n",
    "            url = response.urljoin(next_page[0].extract())\n",
    "            yield scrapy.Request(url, self.parse)\n",
    "\n",
    "    def parse_hotel(self, response):\n",
    "        for href in response.xpath('//div[starts-with(@class,\"quote\")]/a/@href'):\n",
    "            url = response.urljoin(href.extract())\n",
    "            yield scrapy.Request(url, callback=self.parse_review)\n",
    "\n",
    "\n",
    "        next_page = response.xpath('//link[@rel=\"next\"]/@href')\n",
    "        if next_page:\n",
    "            url = response.urljoin(next_page[0].extract())\n",
    "            yield scrapy.Request(url, self.parse_hotel)\n",
    "\n",
    "    def parse_review(self, response):\n",
    "        item = TripadvisorItem()\n",
    "        item['headline'] = response.xpath('translate(//div[@class=\"quote\"]/text(),\"!\",\" \")').extract()[0][1:-1]\n",
    "        item['review'] = response.xpath('translate(//div[@class=\"entry\"]/p,\"\\n\",\" \")').extract()[0]\n",
    "        item['bubbles'] = response.xpath('//span[contains(@class,\"ui_bubble_rating\")]/@alt').extract()[0]\n",
    "        item['date'] = response.xpath('normalize-space(//span[contains(@class,\"ratingDate\")]/@content)').extract()[0]\n",
    "        item['hotel'] = response.xpath('normalize-space(//span[@class=\"altHeadInline\"]/a/text())').extract()[0]\n",
    "        return item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the above code was reworked from that found [here](https://github.com/monkeylearn/hotel-review-analysis) from the team at MonkeyLearn. At the time of writing, the original code no longer appeared to work due apparent changes in TripAdvisor's webpage design and had to be tweaked in order to run correctly.\n",
    "\n",
    "The web scraper (or \"spider\") begins with a base URL. In this case I started at the main page for Island of Hawai'i hotels. The Python class \"TrSpider\" contains three functions for parsing reviews and following links to navigate multiple pages of reviews. Ultimately, the scraper creates a CSV file containing the following features:\n",
    "\n",
    "* Review headline\n",
    "* Review text\n",
    "* Bubble rating\n",
    "* Review date\n",
    "* Hotel/Resort name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bubbles</th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>hotel</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5 of 5 bubbles</td>\n",
       "      <td>2017-07-19</td>\n",
       "      <td>Satisfied Beyond our expectations</td>\n",
       "      <td>Fairmont Orchid, Hawaii</td>\n",
       "      <td>From the moment we arrived at the Fairmont or...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5 of 5 bubbles</td>\n",
       "      <td>2017-07-19</td>\n",
       "      <td>Honeymoon at the Fairmont</td>\n",
       "      <td>Fairmont Orchid, Hawaii</td>\n",
       "      <td>We went there for our honeymoon and were wowe...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3 of 5 bubbles</td>\n",
       "      <td>2017-07-19</td>\n",
       "      <td>Travelguy</td>\n",
       "      <td>Fairmont Orchid, Hawaii</td>\n",
       "      <td>Hotel is in a lovely remote location and is a...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4 of 5 bubbles</td>\n",
       "      <td>2017-06-29</td>\n",
       "      <td>Met our expectations</td>\n",
       "      <td>Wyndham Mauna Loa Village</td>\n",
       "      <td>We stayed here for 7 nights, June 18-25, 2017...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5 of 5 bubbles</td>\n",
       "      <td>2017-06-27</td>\n",
       "      <td>Great hotel with amazing views</td>\n",
       "      <td>Fairmont Orchid, Hawaii</td>\n",
       "      <td>My husband and I stayed here at the beginning...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          bubbles       date                           headline  \\\n",
       "0  5 of 5 bubbles 2017-07-19  Satisfied Beyond our expectations   \n",
       "1  5 of 5 bubbles 2017-07-19          Honeymoon at the Fairmont   \n",
       "2  3 of 5 bubbles 2017-07-19                          Travelguy   \n",
       "3  4 of 5 bubbles 2017-06-29               Met our expectations   \n",
       "4  5 of 5 bubbles 2017-06-27    Great hotel with amazing views    \n",
       "\n",
       "                       hotel  \\\n",
       "0    Fairmont Orchid, Hawaii   \n",
       "1    Fairmont Orchid, Hawaii   \n",
       "2    Fairmont Orchid, Hawaii   \n",
       "3  Wyndham Mauna Loa Village   \n",
       "4    Fairmont Orchid, Hawaii   \n",
       "\n",
       "                                              review rating  \n",
       "0   From the moment we arrived at the Fairmont or...    pos  \n",
       "1   We went there for our honeymoon and were wowe...    pos  \n",
       "2   Hotel is in a lovely remote location and is a...    neg  \n",
       "3   We stayed here for 7 nights, June 18-25, 2017...    pos  \n",
       "4   My husband and I stayed here at the beginning...    pos  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('bihotels.csv', dtype={'bubbles':'category','hotel':'category','review':'str'}, parse_dates=[1])\n",
    "df.dropna(inplace=True)\n",
    "df['rating'] = np.where((df['bubbles'] == '5 of 5 bubbles') | (df['bubbles'] == '4 of 5 bubbles'), 'pos', 'neg')\n",
    "df = df.groupby('hotel').filter(lambda x: len(x) > 100)\n",
    "df['hotel'] = df['hotel'].cat.remove_unused_categories()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some general data clensing is performed to remove records with missing values and dropping hotels with fewer than 100 reviews. This leaves me with 40,806 reviews to work with from over 14 years (4/6/2003 - 7/20/2017).\n",
    "\n",
    "Additional, I created a feature, \"rating,\" combining 4 and 5 bubble reviews (positive) and 1, 2, and 3 bubble reviews (negative) intended to simplify the definition of \"positive review\" from \"negative review.\" \n",
    "\n",
    "One observation to note is the class imbalance introduced by adding this arbitrary split. If I were preparing a classification model I'd want to address this. No other logical splits would appear to remedy this either. An alternative approach perhaps would be to simulate additional reviews for the low scoring reviews (see a method described [here]('http://datamining.rutgers.edu/publication/ipm2010.pdf')). I will simply build an LDA model for *both* positive and negative reviews since their individual sample sizes should be sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x175a69df908>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4sAAAFACAYAAAAVo+k9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xu8XVV97/3PV/BWlQISeCIXQRptwWrUiFjaHpSKgfYp\n9KLCsRItT6MWeuDU9hE8PYVqeV706pFqabFEQqsgFT3k2FhMKehjyyVBkVvkJAItEQ5EQcCjpYX+\nzh9zbFnsufbOzmXvtbP35/16rdea6zfHmGvMmb0y1m/NMcdMVSFJkiRJ0qCnjboBkiRJkqTZx2RR\nkiRJktRjsihJkiRJ6jFZlCRJkiT1mCxKkiRJknpMFiVJkiRJPSaLkiRJkqQek0VJkiRJUs+0JYtJ\n9k9ydZL1SW5LclqL75lkTZIN7XmPFk+S85JsTHJzklcObGtZK78hybKB+KuS3NLqnJck07U/kiRJ\nkjSfpKqmZ8PJQmBhVX05yfOAG4HjgbcDD1bVuUnOAPaoqvcmORb4NeBY4DXAh6rqNUn2BNYBS4Bq\n23lVVT2U5AbgNOA6YDVwXlV9brJ27bXXXnXggQdOwx5LkmaTG2+88ZtVtWDU7dhZ2D9K0vwx1T5y\n1+lqQFXdB9zXlh9Nsh7YFzgOOLIVWwlcA7y3xS+uLnu9LsnuLeE8ElhTVQ8CJFkDLE1yDbBbVV3b\n4hfTJaOTJosHHngg69at23E7KkmalZL806jbsDOxf5Sk+WOqfeSMXLOY5EDgFcD1wD4tkRxLKPdu\nxfYF7hmotqnFJotvGhKXJEmSJG2naU8WkzwXuBw4vaoemazokFhtQ3xYG5YnWZdk3ebNm7fUZEmS\nJEma96Y1WUzydLpE8eNV9ekWvr8NLx27rvGBFt8E7D9QfT/g3i3E9xsS76mqC6pqSVUtWbDAy1ck\nSZIkaUumczbUABcC66vqjwdWrQLGZjRdBlwxED+pzYp6OPBwG6Z6JXB0kj3azKlHA1e2dY8mOby9\n10kD25IkSZIkbYdpm+AGOAJ4G3BLkpta7H3AucBlSU4G/hl4U1u3mm4m1I3Ad4F3AFTVg0k+AKxt\n5d4/NtkN8G7gIuDZdBPbTDq5jSRJkiRpaqZzNtQvMfy6QoCjhpQv4JQJtrUCWDEkvg546XY0U5Ik\nSZI0xIzMhipJkiRJ2rmYLEqSJEmSekwWJUmSJEk9JouSJEmSpB6TRUmSJElSz3TeOkOSNINuP/vX\nRt2EGXfI2X8y6iZI0vd966pLR90EzWHPP+qEGX9PzyxKkiRJknpMFiVJkiRJPSaLkiRJkqQek0VJ\nkiRJUo/JoiRJkiSpx2RRkiRJktRjsihJkiRJ6jFZlCRJkiT1mCxKkiRJknpMFiVJkiRJPSaLkiRJ\nkqQek0VJkmZYkmcluSHJV5PcluR3WvygJNcn2ZDkk0me0eLPbK83tvUHDmzrzBa/I8kbB+JLW2xj\nkjNmeh8lSTs/k0VJkmbeY8Drq+rlwGJgaZLDgd8DPlhVi4CHgJNb+ZOBh6rqh4APtnIkOQQ4ATgU\nWAr8aZJdkuwCfAQ4BjgEOLGVlSRpykwWJUmaYdX5Tnv59PYo4PXAp1p8JXB8Wz6uvaatPypJWvzS\nqnqsqu4CNgKHtcfGqrqzqv4VuLSVlSRpykwWJUkagXYG8CbgAWAN8HXg21X1eCuyCdi3Le8L3APQ\n1j8MPH8wPq7ORHFJkqbMZFGSpBGoqieqajGwH92ZwB8ZVqw9Z4J1Wxt/iiTLk6xLsm7z5s1Ta7gk\nad4wWZQkaYSq6tvANcDhwO5Jdm2r9gPubcubgP0B2vofBB4cjI+rM1F8/HtfUFVLqmrJggULdtQu\nSZLmCJNFSZJmWJIFSXZvy88GfgpYD1wN/GIrtgy4oi2vaq9p6/++qqrFT2izpR4ELAJuANYCi9rs\nqs+gmwRn1fTvmSRpLtl1y0UkSdIOthBY2WYtfRpwWVV9NsntwKVJfhf4CnBhK38h8JdJNtKdUTwB\noKpuS3IZcDvwOHBKVT0BkORU4EpgF2BFVd02c7snSZoLpi1ZTLIC+Bnggap6aYt9EnhJK7I73YX8\ni9v9otYDd7R111XVu1qdVwEXAc8GVgOnVVUl2RP4JHAgcDfw5qp6aLr2R5KkHaWqbgZeMSR+J931\ni+Pj/wK8aYJtnQOcMyS+mq7flCRpm0znMNSL6O759H1V9ZaqWtwu6L8c+PTA6q+PrRtLFJvzgeV0\nQ2sWDWzzDOCqdi+qq9prSZIkSdIOMG3JYlV9kW6oTE+7N9SbgUsm20aShcBuVXVtuzbjYobfc2rw\nXlSSJEmSpO00qglufgK4v6o2DMQOSvKVJF9I8hMtti/djG5jBu8TtU9V3QfQnvee6M2cGlySJEmS\nts6oksUTeepZxfuAA6rqFcCvA59IshtTvE/Uljg1uCRJkiRtnRmfDbXdH+rngVeNxarqMeCxtnxj\nkq8DL6Y7k7jfQPXB+0Tdn2RhVd3Xhqs+MBPtlyRJkqT5YBRnFn8K+FpVfX94abvf1C5t+UV0E9nc\n2YaXPprk8Had40kMv+fU4L2oJEmSJEnbadqSxSSXANcCL0myKcnJbdUJ9Ce2+Ung5iRfBT4FvKuq\nxibHeTfwF8BG4OvA51r8XOANSTYAb2ivJUmSJEk7wLQNQ62qEyeIv31I7HK6W2kMK78OeOmQ+LeA\no7avlZIkSZKkYUY1wY0kSZIkaRYzWZQkSZIk9ZgsSpIkSZJ6TBYlSZIkST0mi5IkSZKkHpNFSZIk\nSVKPyaIkSZIkqcdkUZIkSZLUY7IoSZIkSeoxWZQkSZIk9ZgsSpIkSZJ6TBYlSZIkST0mi5IkSZKk\nHpNFSZIkSVKPyaIkSZIkqcdkUZIkSZLUY7IoSZIkSeoxWZQkSZIk9ZgsSpIkSZJ6TBYlSZIkST0m\ni5IkSZKkHpNFSZIkSVKPyaIkSZIkqcdkUZIkSZLUY7IoSdIMS7J/kquTrE9yW5LTWvzsJN9IclN7\nHDtQ58wkG5PckeSNA/GlLbYxyRkD8YOSXJ9kQ5JPJnnGzO6lJGlnN23JYpIVSR5IcutAzE5QkiR4\nHHhPVf0IcDhwSpJD2roPVtXi9lgN0NadABwKLAX+NMkuSXYBPgIcAxwCnDiwnd9r21oEPAScPFM7\nJ0maG6bzzOJFdB3aeHaCkqR5raruq6ovt+VHgfXAvpNUOQ64tKoeq6q7gI3AYe2xsarurKp/BS4F\njksS4PXAp1r9lcDx07M3kqS5atqSxar6IvDgFIvbCUqS5qUkBwKvAK5voVOT3NxG6OzRYvsC9wxU\n29RiE8WfD3y7qh4fFx//3suTrEuybvPmzTtojyRJc8UorlmcsU5wjJ2hJGk2SvJc4HLg9Kp6BDgf\nOBhYDNwH/NFY0SHVaxviTw1UXVBVS6pqyYIFC7ZhDyRJc9lMJ4sz2gl+f4WdoSRplknydLpE8eNV\n9WmAqrq/qp6oqn8HPko3wga6H0X3H6i+H3DvJPFvArsn2XVcXJKkKZvRZNFOUJIkaJdTXAisr6o/\nHogvHCj2c8DYJHGrgBOSPDPJQcAi4AZgLbCoTfr2DLrr/1dVVQFXA7/Y6i8DrpjOfZIkzT0zmiza\nCUqSBMARwNuA14+bIfz3k9yS5GbgdcB/Bqiq24DLgNuBvwVOaT++Pg6cClxJN0nOZa0swHuBX0+y\nke7yjQtncP8kSXPArlsusm2SXAIcCeyVZBNwFnBkksV0Q0bvBt4JXSeYZKwTfJzWCbbtjHWCuwAr\nxnWClyb5XeAr2AlKknYSVfUlhl9SsXqSOucA5wyJrx5Wr6ru5MkRPJIkbbVpSxar6sQh4QkTOjtB\nSZIkSZo9RjEbqiRJkiRpljNZlCRJkiT1mCxKkiRJknpMFiVJkiRJPSaLkiRJkqQek0VJkiRJUo/J\noiRJkiSpx2RRkiRJktRjsihJkiRJ6jFZlCRJkiT1mCxKkiRJknpMFiVJkiRJPSaLkiRJkqQek0VJ\nkiRJUo/JoiRJkiSpx2RRkiRJktRjsihJkiRJ6jFZlCRJkiT1mCxKkiRJknpMFiVJkiRJPSaLkiRJ\nkqQek0VJkiRJUo/JoiRJkiSpx2RRkiRJktQzbclikhVJHkhy60DsD5J8LcnNST6TZPcWPzDJ95Lc\n1B5/NlDnVUluSbIxyXlJ0uJ7JlmTZEN73mO69kWSJEmS5ptdp3HbFwEfBi4eiK0Bzqyqx5P8HnAm\n8N627utVtXjIds4HlgPXAauBpcDngDOAq6rq3CRntNfvHVJf0k7qW1ddOuomzLjnH3XCqJsgSZIE\nTOOZxar6IvDguNjnq+rx9vI6YL/JtpFkIbBbVV1bVUWXeB7fVh8HrGzLKwfikiRJkqTtNMprFn+Z\n7gzhmIOSfCXJF5L8RIvtC2waKLOpxQD2qar7ANrz3tPdYEmSJEmaL6ZzGOqEkvwX4HHg4y10H3BA\nVX0ryauA/57kUCBDqtc2vN9yuqGsHHDAAdvWaEmSJEmaR2b8zGKSZcDPAG9tQ0upqseq6ltt+Ubg\n68CL6c4kDg5V3Q+4ty3f34apjg1XfWCi96yqC6pqSVUtWbBgwY7eJUmSJEmac2Y0WUyylG4Smp+t\nqu8OxBck2aUtvwhYBNzZhpc+muTwNgvqScAVrdoqYFlbXjYQlyRpVkuyf5Krk6xPcluS01p86Ezf\n6ZzXZga/OckrB7a1rJXf0H6QHYsPnU1ckqSpms5bZ1wCXAu8JMmmJCfTzY76PGDNuFtk/CRwc5Kv\nAp8C3lVVY5PjvBv4C2Aj3RnHsesczwXekGQD8Ib2WpKkncHjwHuq6keAw4FTkhzCkzN9LwKuaq8B\njqH7IXUR3WUV50OXXAJnAa8BDgPOGriV1Nhs4mP1ls7AfkmS5pBpu2axqk4cEr5wgrKXA5dPsG4d\n8NIh8W8BR21PGyVJGoU2cmZskrZHk6ynm8DtOODIVmwlcA3diJzjgIvb5RvXJdm9XYJxJLBm7AfW\nJGuApUmuoc0m3uJjs4kPTiwnSdKkRjkbqiRJ816SA4FXANcz8Uzf+wL3DFQbmx18svhEs4lLkjQl\nJouSJI1IkufSjaw5vaoemazokFhtQ3z8+y9Psi7Jus2bN0+lyZKkecRkUZKkEUjydLpE8eNV9ekW\nnmim703A/gPVx2YHnyw+0Wzi3+ds4ZKkyZgsSpI0w9rMpBcC66vqjwdWTTTT9yrgpDYr6uHAw22Y\n6pXA0Un2aBPbHA1cuYXZxCVJmpJpm+BGkiRN6AjgbcAtSW5qsffRzex9WZtB/J+BN7V1q4Fj6WYG\n/y7wDoCqejDJB4C1rdz7x80mfhHwbLqJbZzcRpK0VUwWJUmaYVX1JYZfVwhDZvpus6CeMsG2VgAr\nhsSHziYuSdJUOQxVkiRJktRjsihJkiRJ6jFZlCRJkiT1mCxKkiRJknpMFiVJkiRJPSaLkiRJkqQe\nk0VJkiRJUo/JoiRJkiSpx2RRkiRJktRjsihJkiRJ6plSspjkqqnEJEmaT+wfJUlz2a6TrUzyLOAH\ngL2S7AGkrdoNeME0t02SpFnJ/lGSNB9MmiwC7wROp+v4buTJzvAR4CPT2C5JkmYz+0dJ0pw3abJY\nVR8CPpTk16rqT2aoTZIkzWr2j5Kk+WBLZxYBqKo/SfJjwIGDdarq4mlqlyRJs579oyRpLptSspjk\nL4GDgZuAJ1q4ADtDSdK8Zf8oSZrLppQsAkuAQ6qqprMxkiTtZOwfJUlz1lTvs3gr8H9NZ0MkSdoJ\n2T9KkuasqZ5Z3Au4PckNwGNjwar62WlplSRJOwf7R0nSnDXVZPHsbdl4khXAzwAPVNVLW2xP4JN0\nkwHcDby5qh5KEuBDwLHAd4G3V9WXW51lwG+1zf5uVa1s8VcBFwHPBlYDpzkUSJI0g84edQMkSZou\nU50N9QvbuP2LgA/z1Av9zwCuqqpzk5zRXr8XOAZY1B6vAc4HXtOSy7Porgsp4MYkq6rqoVZmOXAd\nXbK4FPjcNrZVkqStsh39oyRJs96UrllM8miSR9rjX5I8keSRLdWrqi8CD44LHwesbMsrgeMH4hdX\n5zpg9yQLgTcCa6rqwZYgrgGWtnW7VdW17WzixQPbkiRp2m1r/yhJ0s5gqmcWnzf4OsnxwGHb+J77\nVNV9bbv3Jdm7xfcF7hkot6nFJotvGhLvSbKc7gwkBxxwwDY2W5Kkp9rB/aMkSbPKVGdDfYqq+u/A\n63dwWzLsrbYh3g9WXVBVS6pqyYIFC7ajiZIkTWya+kdJkkZiSmcWk/z8wMun8eT1g9vi/iQL21nF\nhcADLb4J2H+g3H7AvS1+5Lj4NS2+35DykiTNiB3cP0qSNKtMdTbU/3tg+XG6WUyP28b3XAUsA85t\nz1cMxE9NcindBDcPt4TySuD/S7JHK3c0cGZVPdiuFTkcuB44CfiTbWyTJEnbYkf2j5IkzSpTvWbx\nHduy8SSX0J0V3CvJJrpZTc8FLktyMvDPwJta8dV0t83YSHfrjHe0934wyQeAta3c+6tqbNKcd/Pk\nrTM+hzOhSpJm0Lb2j5Ik7QymOgx1P7qzdkfQDa/5Et09DTdNVq+qTpxg1VFDyhZwygTbWQGsGBJf\nB7x00sZLkjRNtrV/lCRpZzDVCW4+RjdM9AV0M47+jxaTJGk+s3+UJM1ZU00WF1TVx6rq8fa4CHBa\nUUnSfGf/KEmas6aaLH4zyS8l2aU9fgn41nQ2TJKknYD9oyRpzppqsvjLwJuB/wXcB/wibQIaSZLm\nMftHSdKcNdVk8QPAsqpaUFV703WOZ09bqyRJ2jlsU/+YZEWSB5LcOhA7O8k3ktzUHscOrDszycYk\ndyR540B8aYttTHLGQPygJNcn2ZDkk0mesaN2WJI0f0w1WXxZVT009qLduuIV09MkSZJ2GtvaP14E\nLB0S/2BVLW6P1QBJDgFOAA5tdf50bNgr8BHgGOAQ4MRWFuD32rYWAQ8BJ2/T3kmS5rWpJotPS7LH\n2IskezLF225IkjSHbVP/WFVfBB7cUrnmOODSqnqsqu6iux/xYe2xsarurKp/BS4FjksS4PXAp1r9\nlcDxU90hSZLGTDXh+yPgH5N8iu4+Um8Gzpm2VkmStHPY0f3jqUlOAtYB72lnLfcFrhsos6nFAO4Z\nF38N8Hzg21X1+JDyT5FkObAc4IADDtiOZkuS5qIpnVmsqouBXwDuBzYDP19VfzmdDZMkabbbwf3j\n+cDBwGK6yXL+qMUz7K23Id4PVl1QVUuqasmCBd7xQ5L0VFMeSlpVtwO3T2NbJEna6eyo/rGq7h9b\nTvJR4LPt5SZg/4Gi+wH3tuVh8W8CuyfZtZ1dHCwvSdKUTfWaRUmSNI2SLBx4+XPA2Eypq4ATkjwz\nyUHAIuAGYC2wqM18+gy6SXBWVVUBV9PdxgNgGXDFTOyDJGlucZIaSZJmWJJLgCOBvZJsAs4Cjkyy\nmG7I6N3AOwGq6rYkl9GdvXwcOKWqnmjbORW4EtgFWFFVt7W3eC9waZLfBb4CXDhDuyZJmkNMFiVJ\nmmFVdeKQ8IQJXVWdw5CJc9rtNVYPid9JN1uqJEnbzGGokiRJkqQek0VJkiRJUo/JoiRJkiSpx2RR\nkiRJktRjsihJkiRJ6jFZlCRJkiT1mCxKkiRJknpMFiVJkiRJPSaLkiRJkqQek0VJkiRJUo/JoiRJ\nkiSpx2RRkiRJktQz48likpckuWng8UiS05OcneQbA/FjB+qcmWRjkjuSvHEgvrTFNiY5Y6b3RZIk\nSZLmql1n+g2r6g5gMUCSXYBvAJ8B3gF8sKr+cLB8kkOAE4BDgRcAf5fkxW31R4A3AJuAtUlWVdXt\nM7IjkiRJkjSHzXiyOM5RwNer6p+STFTmOODSqnoMuCvJRuCwtm5jVd0JkOTSVtZkUZIkSZK206iv\nWTwBuGTg9alJbk6yIskeLbYvcM9AmU0tNlG8J8nyJOuSrNu8efOOa70kSZIkzVEjSxaTPAP4WeCv\nW+h84GC6Iar3AX80VnRI9Zok3g9WXVBVS6pqyYIFC7ar3ZIkSZI0H4xyGOoxwJer6n6AsWeAJB8F\nPttebgL2H6i3H3BvW54oLkmSJEnaDqMchnoiA0NQkywcWPdzwK1teRVwQpJnJjkIWATcAKwFFiU5\nqJ2lPKGVlSRJkiRtp5GcWUzyA3SzmL5zIPz7SRbTDSW9e2xdVd2W5DK6iWseB06pqifadk4FrgR2\nAVZU1W0zthOSJEmSNIeNJFmsqu8Czx8Xe9sk5c8BzhkSXw2s3uENlCRJkqR5btSzoUqSJEmSZiGT\nRUmSJElSj8miJEmSJKnHZFGSJEmS1GOyKEmSJEnqMVmUJEmSJPWYLEqSJEmSekwWJUmSJEk9JouS\nJEmSpB6TRUmSJElSj8miJEkzLMmKJA8kuXUgtmeSNUk2tOc9WjxJzkuyMcnNSV45UGdZK78hybKB\n+KuS3NLqnJckM7uHkqS5wGRRkqSZdxGwdFzsDOCqqloEXNVeAxwDLGqP5cD50CWXwFnAa4DDgLPG\nEsxWZvlAvfHvJUnSFpksSpI0w6rqi8CD48LHASvb8krg+IH4xdW5Dtg9yULgjcCaqnqwqh4C1gBL\n27rdquraqirg4oFtSZI0ZSaLkiTNDvtU1X0A7XnvFt8XuGeg3KYWmyy+aUhckqStYrIoSdLsNux6\nw9qGeH/DyfIk65Ks27x583Y0UZI0F5ksSpI0O9zfhpDSnh9o8U3A/gPl9gPu3UJ8vyHxnqq6oKqW\nVNWSBQsW7JCdkCTNHSaLkiTNDquAsRlNlwFXDMRParOiHg483IapXgkcnWSPNrHN0cCVbd2jSQ5v\ns6CeNLAtSZKmbNdRN0CSpPkmySXAkcBeSTbRzWp6LnBZkpOBfwbe1IqvBo4FNgLfBd4BUFUPJvkA\nsLaVe39VjU2a8266GVefDXyuPSRJ2iomi5IkzbCqOnGCVUcNKVvAKRNsZwWwYkh8HfDS7WmjJEkO\nQ5UkSZIk9ZgsSpIkSZJ6TBYlSZIkST0mi5IkSZKkHie4kWbQnV//+qibMKNedPDBo26CpBFYvfY7\no26C5rhjX/3cUTdBmhdGdmYxyd1JbklyU5J1LbZnkjVJNrTnPVo8Sc5LsjHJzUleObCdZa38hiTL\nJno/SZIkSdLUjXoY6uuqanFVLWmvzwCuqqpFwFXtNcAxwKL2WA6cD11ySXdvqtcAhwFnjSWYkiRJ\nkqRtN+pkcbzjgJVteSVw/ED84upcB+yeZCHwRmBNVT1YVQ8Ba4ClM91oSZIkSZprRpksFvD5JDcm\nWd5i+1TVfQDtee8W3xe4Z6DuphabKC5JkiRJ2g6jnODmiKq6N8newJokX5ukbIbEapL4Uyt3yehy\ngAMOOGBb2ipJkiRJ88rIzixW1b3t+QHgM3TXHN7fhpfSnh9oxTcB+w9U3w+4d5L4+Pe6oKqWVNWS\nBQsW7OhdkSRJkqQ5ZyTJYpLnJHne2DJwNHArsAoYm9F0GXBFW14FnNRmRT0ceLgNU70SODrJHm1i\nm6NbTJIkSZK0HUY1DHUf4DNJxtrwiar62yRrgcuSnAz8M/CmVn41cCywEfgu8A6AqnowyQeAta3c\n+6vqwZnbDUmSJEmam0aSLFbVncDLh8S/BRw1JF7AKRNsawWwYke3UZIkSZLms9l26wxJkiRJ0ixg\nsihJkiRJ6jFZlCRJkiT1mCxKkiRJknpMFiVJkiRJPSaLkiRJkqQek0VJkiRJUo/JoiRJkiSpx2RR\nkiRJktRjsihJkiRJ6jFZlCRJkiT1mCxKkiRJknpMFiVJkiRJPSaLkiRJkqQek0VJkiRJUo/JoiRJ\nkiSpx2RRkiRJktRjsihJkiRJ6jFZlCRpFklyd5JbktyUZF2L7ZlkTZIN7XmPFk+S85JsTHJzklcO\nbGdZK78hybJR7Y8kaedlsihJ0uzzuqpaXFVL2uszgKuqahFwVXsNcAywqD2WA+dDl1wCZwGvAQ4D\nzhpLMCVJmiqTRUmSZr/jgJVteSVw/ED84upcB+yeZCHwRmBNVT1YVQ8Ba4ClM91oSdLOzWRRkqTZ\npYDPJ7kxyfIW26eq7gNoz3u3+L7APQN1N7XYRPGnSLI8ybok6zZv3ryDd0OStLPbddQNkCRJT3FE\nVd2bZG9gTZKvTVI2Q2I1SfypgaoLgAsAlixZ0lsvSZrfPLMoSdIsUlX3tucHgM/QXXN4fxteSnt+\noBXfBOw/UH0/4N5J4pIkTZnJoiRJs0SS5yR53tgycDRwK7AKGJvRdBlwRVteBZzUZkU9HHi4DVO9\nEjg6yR5tYpujW0ySpCmb8WQxyf5Jrk6yPsltSU5r8bOTfKNNFX5TkmMH6pzZpgW/I8kbB+JLW2xj\nkjOGvZ8kSTuRfYAvJfkqcAPwN1X1t8C5wBuSbADe0F4DrAbuBDYCHwV+FaCqHgQ+AKxtj/e3mCRJ\nUzaKaxYfB95TVV9uv57emGRNW/fBqvrDwcJJDgFOAA4FXgD8XZIXt9Ufoes0NwFrk6yqqttnZC8k\nSdrBqupO4OVD4t8CjhoSL+CUCba1Alixo9soSZo/ZjxZbMNjxmZ0ezTJeobM0DbgOODSqnoMuCvJ\nRrrrNwA2to6VJJe2siaLkiRJkrSdRnrNYpIDgVcA17fQqUluTrJi4ObB2zUteHsfpwaXJEmSpK0w\nsmQxyXOBy4HTq+oR4HzgYGAx3ZnHPxorOqT6lKcFh25q8KpaUlVLFixYsN1tlyRJkqS5biT3WUzy\ndLpE8eNV9WmAqrp/YP1Hgc+2l5NN/+204JIkSZI0DUYxG2qAC4H1VfXHA/GFA8V+jm6qcOimBT8h\nyTOTHAQsopshbi2wKMlBSZ5BNwnOqpnYB0mSJEma60ZxZvEI4G3ALUluarH3AScmWUw3lPRu4J0A\nVXVbksvoJq55HDilqp4ASHIq3X2jdgFWVNVtM7kjgtVrvzPqJsyoY1/93FE3QZIkSZoRo5gN9UsM\nv95w9SR1zgHOGRJfPVk9SZIkSdK2GelsqJIkSZKk2clkUZIkSZLUY7IoSZIkSeoxWZQkSZIk9Zgs\nSpIkSZJ6TBYlSZIkST0mi5IkSZKkHpNFSZIkSVKPyaIkSZIkqcdkUZIkSZLUs+uoGzCb/M4F94y6\nCTPurOV4qVqgAAANiUlEQVT7j7oJkiRJkmYhzyxKkiRJknpMFiVJkiRJPSaLkiRJkqQek0VJkiRJ\nUo/JoiRJkiSpx2RRkiRJktRjsihJkiRJ6jFZlCRJkiT1mCxKkiRJknpMFiVJkiRJPSaLkiRJkqQe\nk0VJkiRJUo/JoiRJkiSpZ6dPFpMsTXJHko1Jzhh1eyRJmi3sIyVJ22OnThaT7AJ8BDgGOAQ4Mckh\no22VJEmjZx8pSdpeO3WyCBwGbKyqO6vqX4FLgeNG3CZJkmYD+0hJ0nbZ2ZPFfYF7Bl5vajFJkuY7\n+0hJ0nbZddQN2E4ZEqteoWQ5sLy9/E6SO6a1VdtmL+CbM/2mZ79zpt9xhxnJ8dqJeby2zgiP14mj\nedvtM7rj9TsfnmztC2eqGbPUFvvInaR/nA/8P1rzlX/7W2WHfkeYUh+5syeLm4D9B17vB9w7vlBV\nXQBcMFON2hZJ1lXVklG3Y2fh8do6Hq+t4/HaOh6vWWuLfeTO0D/OB36GNF/5tz/77ezDUNcCi5Ic\nlOQZwAnAqhG3SZKk2cA+UpK0XXbqM4tV9XiSU4ErgV2AFVV124ibJUnSyNlHSpK2106dLAJU1Wpg\n9ajbsQM4DGjreLy2jsdr63i8to7Ha5aaQ33kXOdnSPOVf/uzXKp688FIkiRJkua5nf2aRUmSJEnS\nNDBZlCRJkiT1zOtkMcmKJA8kuXUb6i5Icn2SryT5iXHrLkpyV5Kb2mPxkPpvTzLpDcKG1LkmSW96\n4SRnJ/mNIfEDt2XfJnjv/ZNcnWR9ktuSnLaV9efV8Wrbe1aSG5J8tR2z39nK+j/cjsdXkhw8bt01\nSe4YOGZ7D6k/dD+38J53J9lrSPyiJL84JH5kks9uzXtMoQ27tH3equ3Ox+PV3v+Wtk/rtrLuvPtM\nSpKkrbPTT3CznS4CPgxcvA11jwK+VlXLJlj/m1X1qW1t2Cz0OPCeqvpykucBNyZZU1W3T7H+fDte\nAI8Br6+q7yR5OvClJJ+rquumWP944IqqOmuC9W+tqq1KEHYSpwHrgd22st58PV6vq6ptuaHxfPxM\nSpKkrTCvzyxW1ReBBycrk+SFSa5KcnN7PqD9yv77wLHtV/dnb2MT9k/yt+2Mx1nt/Z7yS3qS30hy\n9kCdX0ryj0luTXLYQPzlSf4+yYYkvzJkP3ZJ8gdJ1rZ9eWeLL0zyxbYft44/wzCmqu6rqi+35Ufp\nvszvO+R9PF5Ndb7TXj69PXozSiVZnOS69j6fSbJHkmOB04H/J8nVUz9EPb39HH92K8mHk7x9oM5v\npjsjekOSHxqI/1SS/z/J/0zyM0P24znpztavbWerjmvxQ9u2bmr7uGiixibZD/hp4C8mKePx2gp+\nJqXRa5+L9Uk+mm6kyeeTPDvJwe0zdGP7/+KHW/mD2/9za5O8P8l3tvQe0mzU/va/lmRl+7/7U0l+\nIMlRre+7pfWFz2zlz01yeyv7h6Nuv+Z5sjhFHwYurqqXAR8Hzquqm4DfBj5ZVYur6ntD6p3T/tA/\nOPYBGOIw4K3AYuBNGTI8a4jnVNWPAb8KrBiIv4zuS/Zrgd9O8oJx9U4GHq6qVwOvBn4lyUHAfwSu\nrKrFwMuBm7bUgCQHAq8Arh+y2uM1oH3BvQl4AFhTVcOO2cXAe9sxuwU4q013/2fAB6vqdRNs/mPt\nC/J/TZIJymxpP4d5pKoOo/u3/G8D8QOB/9C292dJnjWu3n8B/r4ds9cBf5DkOcC7gA+1Y7YE2DTJ\ne/834P8F/n2SMh6vJxXw+fZFc/kEZfxMSrPDIuAjVXUo8G3gF+huG/BrVfUq4DeAP21lP0T3/8Cr\ngXtH0VhpB3oJcEHrhx4Bfp1udN9bqupH6UY6vjvJnsDPAYe2sr87ovZqgMnilr0W+ERb/kvgx6dQ\n50zgh+m+0OwJvHeCcmuq6lvti9qnp7jtS+D7Z0V3S7J7i19RVd9rw9GupvsSN+ho4KSWuFwPPJ+u\n41oLvKP98v+j7azhhJI8F7gcOL2qHhlSxOM1oKqeaF9i9wMOS/LSwfVJfhDYvaq+0EIrgZ+cwn69\ntf0H+xPt8bYJym1pP4e5ZOD5tQPxy6rq36tqA3An3b/ZoKOBM9oxuwZ4FnAAcC3wviTvBV44QWJC\nO/v2QFXdOFHDPF49R1TVK4FjgFOSDDsWfial2eGu9kMNwI10Pyj9GPDX7e/6z4GFbf1rgb9uy59A\n2rndU1X/0Jb/iu4yiLuq6n+22Fhf/gjwL8BfJPl54Lsz3lL1mCxuvS3emLIN2ayqegz4GBN/4Ry/\nraK7NnDw32X82YhhdSaLjwndr5eL2+Ogqvp8+8L2k8A3gL9MctIEbSXddXeXAx+vqk9PVG4L7egX\nmKPH6ykbr/o2XUKwdCrlp7C9b7TnR+m+SEzXMZtoedjrAL8wcMwOqKr1VfUJ4GeB7wFXJnn9BG09\nAvjZJHcDlwKvT/JXE5TdKnP0eFFV97bnB4DPMLXk1s+kNBqPDSw/QfdDzLcH/qYXV9WPjKht0nSa\n0k3dq+pxuv7mcrp5CP52OhulqTFZ3LJ/BE5oy28FvrSlCkkWtufQ/bFPNJvfG5Lsme56oeOBfwDu\nB/ZO8vw29Gv8tU5vadv+cbohWQ+3+HHpZt98PnAk3a/tg66kO8X/9Fb/xemumXoh3dmcjwIXAq+c\nYJ/S1q+vqj+eZPc9Xk/u14KxsyatzT8FfG2wTGvPQ3nyOqu3AV9gEkl2TZuBs7XvZ5j4mA3bz38C\nDknyzHam7qhxdd4y8HztQPxNSZ6WbqbRFwF3jKt3JfBrY0M8k7yiPb8IuLOqzgNW0Q037KmqM6tq\nv6o6kO5v6O+r6pfGlfF4Pblfz0k32RRt+OrRE+yXn0lpdnoEuCvJm6D7vCV5eVt3Hd0wVXjy8yvt\nrA5IMjby5kTg74AD8+R1/m8DvtBGr/1gdZeWnE53iYNGbF7PhprkErovJXsl2UR37dOF44r9J2BF\nkt8ENgPvmMKmP55kAd0v4TfRXYM0zJfohoX9EPCJajM1Jnk/3TCruxiXXNB9Uf5Hupkif3kgfgPw\nN3TD2D5QVfemu7ZwzF/QDXn5cvsCuJnuy92RdBN0/BvwHWCiX+WPoPsw39KGywC8r32gB3m8nrQQ\nWJlkF7ofZi6rqmG3TVhGd03bD9ANV9zSMXsm3RmnpwO70P2n+9EJyvb2EyDJZcDNwAbgK+O3n+T6\n1uYTB+J30CVm+wDvqqp/yVMv/fsA3TV7N7djdjddovAWuklN/g34X8D7t7B/W+Lx6uwDfKZtc1e6\nz8SwX2H9TEqz11uB85P8Ft0kaJcCX6X7ovxXSd5D97l4eOJNSLPeemBZkj+n60dPo/tB5K+T7Er3\n4+Cf0Z1tvyLdNf4B/vOI2qsBqZrSmWFJkiTNgPZj2PeqqpKcAJxYVceNul3S1mo/+n22ql66haKa\npeb1mUVJkqRZ6FXAh9tZ9G/z1LPwkjRjPLMoSZIkSepxghtJkiRJUo/JoiRJkiSpx2RRkiRJktRj\nsijNUkkOTDLR/e2GlT87yW8MiR+ZZNgtO0hy99g9CCVJmg+SnN5mnB17vXrsvsiSnspkUZIkSXNK\nOhN9zz0d+H6yWFXHVtW3Z6Zl0s7FZFGa3XZNsjLJzUk+leQHBs8GJlmS5JqB8i9P8vdJNiT5lYH4\nbkk+k+T2JH82rANN8ktJbkhyU5I/T7JLe1yU5NYktyTxBrmSpFmpjchZn+RPgS8DFyZZl+S2JL/T\nyvwn4AXA1UmubrG7k+w1UP+jrc7nkzy7lXl164uvTfIHWzPyR9qZmSxKs9tLgAuq6mXAI8CvbqH8\ny4CfBl4L/HaSF7T4YcB7gB8FDgZ+frBSkh8B3gIcUVWLgSeAtwKLgX2r6qVV9aPAx3bIXkmSND1e\nAlxcVa8A3lNVS+j6xv+Q5GVVdR5wL/C6qnrdkPqLgI9U1aF097j8hRb/GPCuqnotXR8pzQsmi9Ls\ndk9V/UNb/ivgx7dQ/oqq+l5VfRO4mi5JBLihqu6sqieAS4Zs5yi6m0CvTXJTe/0i4E7gRUn+JMlS\nuoRVkqTZ6p+q6rq2/OYkXwa+AhwKHDKF+ndV1U1t+UbgwHY94/Oq6h9b/BM7tMXSLLbrqBsgaVI1\n5PXjPPlDz7OmUH6y+JgAK6vqzPENSPJy4I3AKcCbgV/ecrMlSRqJ/w2Q5CDgN4BXV9VDSS6i32cO\n89jA8hPAs+n6SGle8syiNLsdkOS1bflE4EvA3XRnAeHJ4TFjjkvyrCTPB44E1rb4YUkOatcqvqVt\nZ9BVwC8m2RsgyZ5JXtiujXxaVV0O/FfglTtu1yRJmja70SWODyfZBzhmYN2jwPOmuqGqegh4NMnh\nLXTCDmulNMt5ZlGa3dYDy5L8ObABOB+4ge6i/fcB148rfwPwN8ABwAeq6t4kLwauBc6lu2bxi8Bn\nBitV1e1Jfgv4fEso/43uTOL3gI8NTIjTO/MoSdJsU1VfTfIV4Da6Syr+YWD1BcDnktw3wXWLw5wM\nfDTJ/wauAR7eke2VZqtUjR+NJkmSJGlMkudW1Xfa8hnAwqo6bcTNkqadZxYlSZKkyf10kjPpvjv/\nE/D20TZHmhmeWZQkSZIk9TjBjSRJkiSpx2RRkiRJktRjsihJkiRJ6jFZlCRJkiT1mCxKkiRJknr+\nDyy3oCu2rz/iAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x175a64c6748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(ncols=2, figsize=(15,5))\n",
    "sns.countplot(df['bubbles'], ax=axs[0], palette='coolwarm')\n",
    "sns.countplot(df['rating'], ax=axs[1], palette='coolwarm', order=['neg','pos'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preperation for Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While Python has an abundance of add-on packages similar to R, my choice is the *gensim* package (with a little help from the NLTK package, too) since it is built specifically for the purpose of Topic Modeling using the LDA algorithm. It also is scalable for large NLP processing jobs and can be multi-threaded to take advantage of multiple compute cores. But first I should describe both Topic Modeling and LDA in overtly simple terms so as not to get bogged down in the underlying complexities:\n",
    "\n",
    "* **Topic Modeling**: Say you have an encyclopedia. Each chapter covers one \"topic.\" If you were to examine each chapter word-for-word, you'd discover that some words appear more often than others in one chapter compared to another (i.e. \"leaves\"/\"roots\" would probably appear much more frequently in a chapter about \"Trees\" but less frequently, if at all, in a chapter about \"Automobiles\"). Topic Modeling generates sets of commonly co-occuring words found within documents. It's up to the analyst to determine what the *latent* structure is within the word sets and thus what topic they best represent. Since our \"encyclopedia\" in this case are just the sets of positive and negative reviews, we don't know what the chapters/topics are yet. Topic modeling will unveil those through our interpretations.\n",
    "\n",
    "\n",
    "* **LDA**: LDA is probably the most common algorithm for discovering these underlying topics. We choose a number of topics we want it to find in our encyclopedia (this is more of an analytics *art* than *science*). LDA then goes through word-by-word and assigns each word to a random topic. This isn't very helpful initially so we need to find the *best* topic for each word. LDA does this by calculating the proportion of words in the encyclopedia that are currently assigned to a topic and the proportion of assignments to a topic within the encyclopedia for a given word. We essentially want to group words together that have a high probability of co-occuring in a specific topic. LDA iteratively reassigning words to new topics until words stop moving around as much (\"convergence\") because we've begun to find the best sets for them to belong in. We are left with word sets for each topic (remember *we* chose the number of topics to find, not LDA), the probability of each occuring within a topic, and the probability of a topic occuring within the whole encyclopedia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### NLP Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Before I can apply LDA to our set of reviews, I need to perform a few NLP preperation steps to get the text in the correct form for analysis. Here are the three I'll perform below:\n",
    "\n",
    "* Remove **stopwords** from our reviews, or, words with little intrinsic value to our Topic Model. This includes words like \"and,\" \"the,\" \"or,\" etc. I am left with only meaningful words for LDA to iterate through. So an example sentence like *\"The rooms were very spacious and comfortable\"* would become *\"rooms spacious comfortable.\"* (NOTE: words that are considered stopwords can vary by source.)\n",
    "\n",
    "\n",
    "* Convert the words to **lowercase.** This is so we don't consider words at the beginning of sentences as different from those within a sentence (e.g. \"Beach\" and \"beach\").\n",
    "\n",
    "\n",
    "* **Tokenize** our words, or, transform reviews from blocks of text into vectors of individual words. So now instead of our sentence I'd have each individual word on their own: *\"room,\" \"very,\" \"space,\" \"comfort.\"* Each word is now called a \"token.\"\n",
    "\n",
    "There are other data cleaning transformations I could perform in NLP like **stemming** and **lemmatization** but they might not be well suited for this purpose but I will explore them later depending on how our topics/word sets look following LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenizer(reviews):\n",
    "    return [[token for token in simple_preprocess(review) if token not in STOPWORDS] \n",
    "            for review in reviews]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *gensim* package contains the method *simple_preprocess* which applies all three of the above mentioned NLP preprocessing techniques and leaves me with a prepared list for LDA. I'll do this for both positive and negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos = df[df['rating'] == 'pos']\n",
    "neg = df[df['rating'] == 'neg']\n",
    "pos_reviews = (pos['review']).tolist()\n",
    "neg_reviews = (neg['review']).tolist()\n",
    "pos_review_tokens = tokenizer(pos_reviews)\n",
    "neg_review_tokens = tokenizer(neg_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag-of-Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our list of tokens for each review, I now need to turn them into something I can process with LDA. The first step is to create a dictionary for our tokens. This isn't a dictionary in the traditional sense of the word, but rather a list containing each unique token in our collection of reviews with a unique integer ID assigned to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_dic = corpora.Dictionary(pos_review_tokens)\n",
    "pos_dic.filter_n_most_frequent(4)\n",
    "neg_dic = corpora.Dictionary(neg_review_tokens)\n",
    "neg_dic.filter_n_most_frequent(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I go back through our token vectors and count how many times each appears in a review. The end result is a tuple (Token ID, Frequency) for every unique token in each reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>freq</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>moment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>arrived</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>fairmont</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>orchid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>treated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>incredibly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>encountered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>beautiful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>clean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>variety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>accomodate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>different</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>tastes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>activities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>equipment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>ve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>experienced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>property</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>truly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>gorgeous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>takes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>pride</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>felt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>guest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>making</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>valuable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>vacation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>memorable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  freq        token\n",
       "0    0     1       moment\n",
       "1    1     1      arrived\n",
       "2    2     1     fairmont\n",
       "3    3     1       orchid\n",
       "4    4     1      treated\n",
       "5    5     1   incredibly\n",
       "6    6     2       member\n",
       "7    7     1  encountered\n",
       "8    8     1    beautiful\n",
       "9    9     1        clean\n",
       "10  10     1   restaurant\n",
       "11  11     1      variety\n",
       "12  12     1      perfect\n",
       "13  13     1   accomodate\n",
       "14  14     1    different\n",
       "15  15     1       tastes\n",
       "16  16     1   activities\n",
       "17  17     1    available\n",
       "18  18     1    equipment\n",
       "19  19     1          use\n",
       "20  20     1           ve\n",
       "21  21     1  experienced\n",
       "22  22     2     property\n",
       "23  23     2        truly\n",
       "24  24     1     gorgeous\n",
       "25  25     1        takes\n",
       "26  26     1        pride\n",
       "27  27     1          job\n",
       "28  28     1         felt\n",
       "29  29     1        guest\n",
       "30  30     1        thank\n",
       "31  31     1       making\n",
       "32  32     1     valuable\n",
       "33  33     1     vacation\n",
       "34  34     1         time\n",
       "35  35     1    memorable"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_bow = [pos_dic.doc2bow(review) for review in pos_review_tokens]\n",
    "neg_bow = [neg_dic.doc2bow(review) for review in neg_review_tokens]\n",
    "pos_tokens = pd.DataFrame(list(pos_dic.token2id.items()), columns=['token','id'])\n",
    "pos_dt = pd.DataFrame(pos_bow[0], columns=['id','freq'])\n",
    "pos_dt.merge(pos_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example above is a review with 37 unique tokens and their frequency within the given review. Most words appear only once, but others like \"staff\" and \"property\" appear two times. This process is performed across all reviews.\n",
    "\n",
    "I am left with what is called a \"bag-of-words\" representation. A bag-of-words is just a numeric representation of unique word frequency across a collection (or \"corpus\") of texts. It doesn't account for any other linguistic features that might influence our topic model like part-of-speech (is the word a noun, verb, adjective?) or context (does \"drive\" mean \"drive a vehicle\" or \"motivation?\").\n",
    "\n",
    "Unique word frequencies alone won't help me build a LDA topic model. I'll need to perform another transformation called \"Term Frequency - Inverse Document Frequency,\" or TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_tfidf = models.TfidfModel(pos_bow, id2word=pos_dic)\n",
    "neg_tfidf = models.TfidfModel(neg_bow, id2word=neg_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_freq = {k: neg_tfidf.dfs.get(v) for v, k in neg_dic.id2token.items()}\n",
    "sorted(neg_freq.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_freq = {k: pos_tfidf.dfs.get(v) for v, k in pos_dic.id2token.items()}\n",
    "sorted(pos_freq.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_dic.id2token.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  [('nice', 0.010715318554323),\n",
       "   ('stay', 0.0089187182943643844),\n",
       "   ('clean', 0.0084357610019744067),\n",
       "   ('good', 0.0079133698463915748),\n",
       "   ('rooms', 0.0072932551445795829),\n",
       "   ('night', 0.0071981160786825718),\n",
       "   ('area', 0.0065826343367681858),\n",
       "   ('pool', 0.0064615962952416835),\n",
       "   ('place', 0.0061587348449357194),\n",
       "   ('stayed', 0.0060768478688020466)]),\n",
       " (1,\n",
       "  [('beach', 0.01702886930790818),\n",
       "   ('resort', 0.013845659056530875),\n",
       "   ('pool', 0.012189525326125134),\n",
       "   ('ocean', 0.008703470510626558),\n",
       "   ('nice', 0.0082752681033945175),\n",
       "   ('good', 0.007960575054821336),\n",
       "   ('food', 0.0072659713581628644),\n",
       "   ('day', 0.0065215449132699534),\n",
       "   ('kids', 0.006257866296300897),\n",
       "   ('island', 0.0061482715093284599)]),\n",
       " (2,\n",
       "  [('beach', 0.014137524024535265),\n",
       "   ('resort', 0.012137244650710697),\n",
       "   ('service', 0.011637524444420911),\n",
       "   ('mauna', 0.0091302812535893167),\n",
       "   ('stay', 0.0089521250619340222),\n",
       "   ('seasons', 0.0078377857137161989),\n",
       "   ('beautiful', 0.0074541888887023153),\n",
       "   ('best', 0.0070554632330757858),\n",
       "   ('pool', 0.0068193750139612782),\n",
       "   ('food', 0.0065557210977173763)])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_lda = models.LdaModel(pos_bow, id2word=pos_dic, num_topics=3, chunksize=10000, passes=4, iterations=100)\n",
    "pos_lda.show_topics(formatted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  [('night', 0.0079849722665773452),\n",
       "   ('staff', 0.0077369225808560649),\n",
       "   ('pool', 0.0068612636606136899),\n",
       "   ('great', 0.0064278566151871157),\n",
       "   ('view', 0.0063113463136322996),\n",
       "   ('place', 0.0061562918669628604),\n",
       "   ('like', 0.0060575353954311966),\n",
       "   ('good', 0.0058646773285972939),\n",
       "   ('day', 0.0056251754066972736),\n",
       "   ('stayed', 0.0052178321798632358)]),\n",
       " (1,\n",
       "  [('resort', 0.012705358256310929),\n",
       "   ('ocean', 0.0098423563151825502),\n",
       "   ('nice', 0.0068987525290066009),\n",
       "   ('hilton', 0.0068450665852559898),\n",
       "   ('view', 0.0064948362301701142),\n",
       "   ('time', 0.0064565074708988184),\n",
       "   ('pool', 0.006431593289282612),\n",
       "   ('day', 0.0063042078114026222),\n",
       "   ('beach', 0.006267685346002352),\n",
       "   ('good', 0.0061408218572786763)]),\n",
       " (2,\n",
       "  [('service', 0.0082982484383522896),\n",
       "   ('beach', 0.0079432532475636457),\n",
       "   ('good', 0.0077331119133226874),\n",
       "   ('nice', 0.0075149210089646441),\n",
       "   ('pool', 0.0068470485282220534),\n",
       "   ('staff', 0.0066147045630844817),\n",
       "   ('food', 0.0060905800420744359),\n",
       "   ('property', 0.0055874798340021696),\n",
       "   ('like', 0.0053850156932967845),\n",
       "   ('resort', 0.0051929595376778949)])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_lda = models.LdaModel(neg_bow, id2word=neg_dic, num_topics=3, chunksize=10000, passes=4, iterations=100)\n",
    "neg_lda.show_topics(formatted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
